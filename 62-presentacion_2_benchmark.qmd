---
title: "Benchmark geoespacial: cÃ³mo leer los resultados"
subtitle: "Una comparaciÃ³n de stacks, no de lenguajes"
author: "Laboratorio de ProgramaciÃ³n SIG"
format:
  revealjs:
    theme: simple
    slide-number: true
    transition: fade
    incremental: true
    center: true
---

## Â¿QuÃ© estamos comparando?

Este ejercicio **no compara lenguajes de programaciÃ³n**.

EvalÃºa el rendimiento del **stack completo**:

- GDAL (Geospatial Data Abstraction Library): raster (GDAL) + vector (OGR: OpenGIS Simple Features Reference Implementation)
- LibrerÃ­as raster
- Modelo de ejecuciÃ³n
- Nivel de abstracciÃ³n

ğŸ‘‰ El lenguaje es solo una parte del sistema.

---

## Â¿QuÃ© hace exactamente el benchmark?

El benchmark ejecuta un **caso extremo y muy simplificado**:

- Usa **una sola banda raster**
- Aplica **una operaciÃ³n matemÃ¡tica simple** (Ã— 1.5)
- Calcula **una media global**

ğŸ¯ DiseÃ±ado para forzar la lectura completa de los datos.

---

## Â¿QuÃ© NO evalÃºa?

Este benchmark **no evalÃºa**:

- AnÃ¡lisis multibanda
- Operaciones espaciales complejas
- Vecindarios, mÃ¡scaras o reproyecciones
- Flujos iterativos o modelos estadÃ­sticos

ğŸš« No representa un flujo SIG real completo.

---

## Â¿Por quÃ© usamos `mean()`?

El cÃ¡lculo de la media es clave porque:

- Obliga a **recorrer todos los pÃ­xeles**
- Garantiza que la operaciÃ³n aritmÃ©tica fue ejecutada
- Fuerza la evaluaciÃ³n completa del raster

âš ï¸ Cada motor implementa este paso de forma distinta.

---

## Modelos de ejecuciÃ³n comparados

Cada stack sigue una filosofÃ­a diferente:

- **Python / rasterio + NumPy**  
  Lectura completa a memoria + ejecuciÃ³n inmediata

- **R / terra**  
  Ãlgebra de rÃ¡ster optimizado en C++ y procesamiento por bloques, pero sin exponer un pipeline diferido composable

- **R / stars**  
  Manejo de cubos de datos multidimensionales y metadatos ricos; el modo `proxy` difiere la lectura, pero **no construye un DAG composable completo**

- **Julia / Rasters.jl**  
  Flujos *lazy* y **pipelines composables**, evaluados al final como un plan coherente

---

## Â¿QuÃ© favorece este benchmark?

Este escenario favorece motores optimizados para:

- Recorridos contiguos de memoria
- Operaciones simples en una sola pasada
- Reducciones globales monolÃ­ticas

ğŸ‘‰ No todos los motores estÃ¡n diseÃ±ados para este patrÃ³n.

---

## AbstracciÃ³n vs rendimiento

MÃ¡s abstracciÃ³n implica:

- MÃ¡s metadatos
- MÃ¡s coordinaciÃ³n interna
- MÃ¡s costo administrativo

Pero tambiÃ©n ofrece:

- CÃ³digo mÃ¡s claro
- Menos errores
- Mayor expresividad analÃ­tica

âš–ï¸ Es un intercambio inevitable.

---

## Niveles de abstracciÃ³n por motor

| Motor | Nivel de abstracciÃ³n | Forma de trabajar |
|---|---|---|
| **NumPy / rasterio** | Baja | â€œAquÃ­ tienes un arreglo, calcula ahoraâ€ |
| **terra (R)** | Media | â€œYo optimizo internamente en C++â€ |
| **stars (R)** | Alta | â€œGestiono dimensiones, tiempo y metadatosâ€ |
| **Rasters.jl (Julia)** | Flexible | â€œDefino un pipeline que se evalÃºa al finalâ€ |

ğŸ“Œ MÃ¡s abstracciÃ³n = mÃ¡s expresividad, pero mÃ¡s costo administrativo.

---

## Paralelismo y pipelines composables

Solo algunos stacks permiten **componer operaciones** y ejecutarlas al final:

- **Julia (Rasters.jl)**  
  Pipelines composables + **paralelismo multihilo nativo**,  
  sin librerÃ­as externas adicionales

- **Python (xarray + Dask)**  
  Pipelines lazy con ejecuciÃ³n distribuida explÃ­cita

- **R (dplyr + dbplyr)**  
  Lenguaje de pipelines, **no espacial por sÃ­ mismo**;  
  requiere backends como PostGIS, DuckDB o Spark

ğŸ“Œ OptimizaciÃ³n interna **no equivale** a pipeline composable.

---

## No hay un ganador universal

Este benchmark mide:

> Rendimiento bajo un patrÃ³n especÃ­fico de acceso y reducciÃ³n global

No mide:

- Calidad general del lenguaje
- Flexibilidad analÃ­tica
- Escalabilidad en flujos SIG complejos

ğŸ“ Los resultados deben interpretarse con contexto.

---

## Escalando a datos realmente grandes

En proyectos reales con grandes volÃºmenes de datos se consideran:

- Cloud Optimized GeoTIFF (COG)
- Zarr
- GeoParquet
- Procesamiento por bloques
- Infraestructura virtualizada - cloud / HPC - High-Performance Computing (AWS - GCP - Azure)

ğŸ‘‰ La **arquitectura de datos** suele importar mÃ¡s que el lenguaje.

---

## Mensaje final del Benchmark

Este ejercicio sirve para:

- Entender costos reales de lectura y abstracciÃ³n
- Leer benchmarks de forma crÃ­tica
- Elegir herramientas segÃºn el problema

ğŸ¯ No existe el â€œlenguaje mÃ¡s rÃ¡pidoâ€  
existe el **stack adecuado para cada tarea**.


---

## Â¿QuÃ© es lo importante hoy (y quÃ© no)?

En este punto del curso:

âŒ **No es importante** entender cada lÃ­nea de cÃ³digo  
âŒ No es importante memorizar sintaxis  
âŒ No es importante â€œser rÃ¡pido programandoâ€

âœ… **SÃ­ es importante**:

- Ver el **panorama completo** de la programaciÃ³n SIG actual  
- Entender que existen **mÃºltiples stacks y enfoques**
- Reconocer que el rendimiento depende de **arquitectura**, no solo del lenguaje

ğŸ‘‰ El cÃ³digo lo aprenderemos paso a paso.

---

## Â¿QuÃ© estamos aprendiendo realmente?

MÃ¡s allÃ¡ del benchmark, este laboratorio busca que ustedes aprendan a:

- Usar **GitHub** como bitÃ¡cora de trabajo
- Documentar con **Quarto**
- Ejecutar anÃ¡lisis en **Jupyter Lab**
- Trabajar en **VSCode**
- Usar la **terminal** (Windows / Linux)
- Ejecutar entornos reproducibles con **Docker**
- Correr el mismo proceso **de muchas formas distintas**

ğŸ¯ Programar SIG hoy es saber **orquestar herramientas**, no solo escribir cÃ³digo.

---

## El lÃ­mite lo ponen ustedes

En clase aprenderemos:

- Los conceptos fundamentales
- Las herramientas base
- Los patrones comunes de trabajo

Pero el verdadero aprendizaje vendrÃ¡ de:

- Sus **proyectos**
- Su **trabajo individual**
- Lo que decidan explorar mÃ¡s allÃ¡ del aula

ğŸš€ En programaciÃ³n SIG,  
**el lÃ­mite no lo pone el lenguaje, lo pone la curiosidad y el problema que quieran resolver.**
