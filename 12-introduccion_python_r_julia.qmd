---
title: "Introducción a Python, R y Julia"
author: "Alexys H. Rodríguez-Avellaneda, PhD"
date: last-modified
format:
  html:
    toc: true
    code-fold: true
    embed-resources: true
    theme: cosmo
  pdf:
    keep-tex: true       # Esta es la etiqueta que buscas
    toc: true
    number-sections: true
    colorlinks: true
    papersize: letter
    #mermaid-format: png
    # Forzamos a Quarto a usar nuestro wrapper
    #chrome: /usr/local/bin/quarto-browser
execute-dir: project # Asegura contexto limpio
execute:
  cache: false        # Desactiva la caché de knitr
  freeze: false       # No congela resultados previos
  echo: true
  warning: false
  message: false
  daemon: false      # Evita que procesos en segundo plano interfieran
  enabled: true      # Asegura la ejecución
engine: knitr
---


## Funciones j_eval y j_plot en R

```{r}
#| label: j_eval_j_plot
#| code-fold: true
#| include: false
source("./docs/j_eval_j_plot.r")
```


## Introducción

Este capítulo presenta una **introducción práctica y comparativa** a los lenguajes **Python, R y Julia**, enfocada en el uso de **comandos básicos** y en la lectura e interpretación de resultados en consola. El objetivo no es profundizar en programación avanzada, sino ofrecer una **puerta de entrada común** para estudiantes que se inician en el uso de herramientas computacionales para geocomputación.


### Ejecución de código en cada lenguaje

- **Python** y **R** se ejecutan de forma nativa mediante *code chunks* estándar.
- **Julia**, en este curso, **no se ejecuta directamente**. Todo el código Julia se evalúa desde R utilizando funciones auxiliares:
  - `j_eval()` para ejecutar instrucciones generales
  - `j_plot()` para generar gráficos

Por esta razón, en el documento encontrarás dos tipos de bloques relacionados con Julia:

- Bloques con **código Julia puro**, que sirven como referencia y pueden copiarse y reutilizarse.
- Bloques en **R** que llaman a `j_eval()` o `j_plot()`, que son los que realmente ejecutan el código.

### Sobre los bloques de código

- **Todos los bloques de código tienen un `label`**, lo que permite su correcta identificación y reutilización.
- Algunos bloques están pensados **exclusivamente para HTML** y no se ejecutan. Su función es permitir que el estudiante **copie y pegue el código** directamente en su entorno de trabajo.
- Cuando un bloque no se ejecuta, esto se indica explícitamente en sus opciones.

### Alcance del capítulo

En este capítulo aprenderás a:

- Acceder a la ayuda y documentación básica en cada lenguaje
- Ejecutar comandos simples y entender su salida
- Reconocer tipos de objetos y estructuras básicas
- Comparar cómo Python, R y Julia resuelven tareas similares

Este contenido servirá como base para los capítulos posteriores, donde se utilizarán estos lenguajes para la creación de mapas, análisis de datos espaciales y visualización geográfica.


## Ayuda y documentación

| Tarea | Descripción | Python | R | Julia |
|---|---|---|---|---|
| Ver ayuda general | Abre la documentación interactiva | `help()` | `help.start()` | `?` en REPL |
| Ayuda de función | Documentación de un comando | `help(sum)` | `?mean` | `?sum` |
| Ver ejemplos | Código de ejemplo de una función | **Docstrings** | `example("lapply")` | **Docstrings** |
| Vignettes / guías | Tutoriales extendidos | `obj.__doc__` | `browseVignettes()` | `?Modulo` |
| Demo | Ejecutar ejemplos | `libreria.ejemplos()`* | `demo()` | `include("test")`* |

**Nota sobre los Docstrings:** En Python y Julia, la documentación y los ejemplos de uso residen directamente dentro del código fuente en bloques llamados *Docstrings*. Al ejecutar los comandos de ayuda (`help()` o `@doc`), el intérprete extrae estos comentarios y los muestra en la terminal, permitiendo que el usuario vea ejemplos reales de implementación de inmediato sin necesidad de manuales externos.

**Nota sobre los Demos (\*):** A diferencia de R, Python y Julia no tienen un comando universal `demo()`. El asterisco indica que el acceso a ejemplos depende de la librería. En Python, se suele explorar la propiedad `__doc__` o módulos de `datasets`. En Julia, se acostumbra a inspeccionar la carpeta de instalación mediante `pathof(Modulo)` para encontrar archivos de prueba o ejemplos.

::: {.panel-tabset}

### Python
```{python}
#| label: ayuda_python
#| eval: false
# help() busca y muestra el "Docstring" de la función
help(sum)

# Ayuda sobre un módulo completo para ver sus funciones disponibles
import math
help(math)

# dir() lista todos los métodos y atributos (la "anatomía" del objeto)
import pandas as pd
dir(pd.DataFrame)

# pydoc renderiza la documentación técnica en la terminal
import pydoc
print(pydoc.render_doc("math")) 

# Ejemplo de "Demo" en Python (vía datasets de una librería SIG)
import geopandas as gpd
# Listamos los mapas de ejemplo que vienen con la librería
print(gpd.datasets.available)
```

### R
```{r}
#| label: ayuda_r
#| eval: false
# Inicia el servidor de ayuda local en formato HTML
help.start()

# Acceso rápido a la documentación de una función específica
?mean
help("plot")

# Ejecuta automáticamente el código de ejemplo del manual
example("lapply")

# --- Vignettes y Demos ---

# Abre el índice de tutoriales detallados (vignettes)
browseVignettes()

# Listar guías del paquete 'stars' (análisis de cubos de datos)
# Nota: presione "q" al final de la lista para liberar la consola
vignette(package = "stars")

# Visualizar una vignette específica por su nombre
vignette("stars1", package = "stars")

# Importante: requiere dispositivo gráfico (ej. httpgd::hgd())
# presione "q" al final de la lista para salir
demo()

# Demos específicos de librerías de Geomática
library(sf)
demo("nc", package = "sf")
demo("ggplot", package = "sf")
```

### Julia

```{julia}
#| label: ayuda_julia_codigo
#| eval: false
# Este comando (?) solo funciona dentro del REPL interactivo
# ?sum

# En Quarto usamos la macro @doc para acceder al Docstring
@doc sum
@doc println

# Julia usa docstrings con ejemplos y ayuda integrados, similar a Python
# Para encontrar "Demos", localizamos la carpeta del paquete en el disco
using DataFrames
println("Ubicación del código: ", pathof(DataFrames))
```

:::

## Instalación y carga de paquetes

| Tarea | Descripción | Python | R | Julia |
|---|---|---|---|---|
| Instalar paquete | Agregar librerías externas | `pip3 install ...` | `install.packages()` | `Pkg.add()` |
| Cargar paquete | Habilitar funciones del paquete | `import ...` | `library()` | `using ...` |

::: {.panel-tabset}

### Python
```{.python}
#| label: instalacion_python
# #| eval: false

# En terminal usamos pip3 
# para asegurar la versión de Python 3.x
# pip3 install colorama

# Dentro de python usamos el prefijo "!"
# !pip3 install colorama

# Cargamos solo lo necesario para manejar colores en consola
from colorama import Fore, Style

print("Librería cargada en Python")

# Aparecerán caracteres especiales al inicio del texto
# porque el HTML no entiende la instrucción colorear en rojo
# Fore.RED aplica el color; Style.RESET_ALL evita que el color "manche" las siguientes líneas
print(Fore.RED + "Librería cargada en Python" + Style.RESET_ALL)
```

### R
```{r}
#| label: instalacion_r
# #| eval: false

# Este comando carga el paquete con require() o lo instala
# si no existe
if (!require("crayon", character.only = TRUE)) {
  install.packages("crayon", dependencies = TRUE, repos = "https://cran.rstudio.com/")
}

# Activamos el paquete para la sesión actual de R
library(crayon)

# cat() interpreta los códigos de escape ANSI que generan los colores
cat(red("Librería cargada en R"))
```

### Julia

::: {.content-visible when-format="html"}
::: {.callout-tip collapse="true" icon="false"}
#### ▷ CÓDIGO PURO (Copiar y Pegar)
```{julia}
#| label: instalacion_julia_codigo
#| eval: false
# Cargamos el gestor de paquetes de Julia
using Pkg
# Instalamos la librería Crayons
Pkg.add("Crayons")

# Cargamos la librería para habilitar sus funciones
using Crayons

println("Librería cargada en Julia")

# Aparecerán caracteres especiales al inicio del texto
# porque el HTML no entiende la instrucción colorear en rojo
# println con Crayon permite aplicar estilos directamente
println(Crayon(foreground=:red), "Librería cargada en Julia")
```
:::
:::

```{.julia}
#| label: instalacion_julia_ejecucion
#| kernel: julia-1.10
#| results: asis
# #| eval: false
#j_eval('
using Pkg
# Verificamos si "Crayons" ya está en el proyecto; si no, lo instalamos
if !haskey(Pkg.dependencies(), Base.UUID("a83e43d3-9d41-5979-9952-4e448995a975"))
    Pkg.add("Crayons")
end
using Crayons
println("Librería cargada en Julia")

# Aparecerán caracteres especiales al inicio del texto
# porque el HTML no entiende la instrucción colorear en rojo
println(Crayon(foreground=:red), "Librería cargada en Julia")
#')
```
:::

## Objetos básicos y estructuras de datos

El manejo eficiente de vectores y matrices es el corazón del procesamiento ráster. A continuación, se presenta una comparativa de cómo se declaran y manipulan los objetos básicos.


| Estructura | Descripción | Python | R | Julia |
|:--- |:--- |:--- |:--- |:--- |
| **Vector** | Colección lineal ordenada | `v = np.array([1, 2, 3])` | `v <- c(1, 2, 3)` | `v = [1, 2, 3]` |
| **Matriz** | Arreglo bidimensional (Ráster) | `m = np.zeros((3,3))` o `np.array([[...]])` | `m <- matrix(0, 3, 3)` | `m = zeros(3, 3)` o `[... ; ...]` |
| **Diccionario** | Pares clave-valor (Metadatos) | `{key: val}` ej. `{"id": 1}` | `list(k=v)` ej. `list(id = 1)` | `Dict(k=>v)` ej. `Dict("id"=>1)` |
| **Data Frame** | Estructura tabular (Atributos) | `pd.DataFrame()` | `data.frame()` | `DataFrame(...)` |
| **Indexación** | Posición del primer elemento | Inicia en **0** | Inicia en **1** | Inicia en **1** |

: Comparativa de estructuras de datos {#tbl-comparativa-datos}

### Relación entre estructuras y componentes SIG {#sec-diagrama-estructuras}

Para entender por qué usamos diferentes estructuras de datos, es útil ver cómo se mapean con los componentes de un Sistema de Información Geográfica:



::: {#fig-relacion-geo}
![](images/fig-relacion-geo.png){width=100%}
Mapeo de estructuras de programación a componentes de datos espaciales.
:::



::: {.callout-note}
Como se observa en la @fig-relacion-geo, la **Matriz** es la estructura reina para el análisis ráster, mientras que los **DataFrames** son los que nos permiten realizar consultas sobre las bases de datos de predios o coberturas.
:::

::: {.callout-warning}
### El peligro de la indexación espacial
Esta es la fuente más frecuente de errores. Mientras que en **Python** el primer píxel de una banda satelital es el `[0,0]`, en **R** y **Julia** es el `[1,1]`. Un error de este tipo desplazará todos sus resultados una celda, invalidando análisis de precisión o cambios de cobertura.
:::





**Nota sobre estructuras:** En Geomática, los vectores suelen representar coordenadas o valores de píxeles, mientras que los diccionarios son fundamentales para manejar atributos (como en formato JSON o GeoJSON). Las tablas (DataFrames) son el estándar para bases de datos alfanuméricas de predios, municipios o estaciones climáticas.

::: {.panel-tabset}

### Python
```{python}
#| label: objetos_python
# #| eval: false
# 1. Listas: colecciones mutables de elementos
# Ejemplo: Códigos DANE de departamentos (Antioquia, Cundinamarca, Valle)
codigos = [5, 25, 76]
type(codigos)

# 2. Diccionarios: Estructuras de clave-valor
# Ideal para representar metadatos de un departamento
metadatos = {
    "departamento": ["Antioquia", "Cundinamarca", "Valle"],
    "area_km2": [63612, 22623, 22140],
    "capital": ["Medellín", "Bogotá", "Cali"]
}
type(metadatos)

# 3. DataFrames: Para manejar tablas de atributos SIG
import pandas as pd
df_colombia = pd.DataFrame(metadatos)
type(df_colombia)

# Visualizamos el resumen técnico de la tabla
print(df_colombia.info())
```


### R
```{r}
#| label: objetos_r
# #| eval: false
# 1. Vectores: La unidad básica en R (todos los elementos del mismo tipo)
# Códigos DANE de departamentos
codigos <- c(5, 25, 76)
class(codigos)

# 2. Listas: Pueden contener objetos de diferentes tipos y tamaños
# En R, las listas con nombres funcionan como los diccionarios
metadatos <- list(
  departamento = c("Antioquia", "Cundinamarca", "Valle"),
  area_km2 = c(63612, 22623, 22140),
  capital = c("Medellín", "Bogotá", "Cali")
)
class(metadatos)

# 3. Data Frame: La estructura tabular nativa por excelencia
df_colombia <- data.frame(metadatos)
class(df_colombia)

# str() muestra la estructura interna del objeto (equivalente a info() en Python)
str(df_colombia)
```


### Julia

::: {.content-visible when-format="html"}
::: {.callout-tip collapse="true" icon="false"}
#### ▷ CÓDIGO PURO (Copiar y Pegar)
```{julia}
#| label: objetos_julia_codigo
#| eval: false
# 1. Vectores: Se definen con corchetes (similar a Python)
codigos = [5, 25, 76]
typeof(codigos)

# 2. Diccionarios: Se usa el operador => para asociar clave y valor
metadatos = Dict(
    "departamento" => ["Antioquia", "Cundinamarca", "Valle"],
    "area_km2" => [63612, 22623, 22140]
)
typeof(metadatos)

# 3. Tablas: En Julia Base se pueden usar vectores de Tuplas Nombradas,
# pero en Geomática siempre usaremos la librería DataFrames
using DataFrames
df_colombia = DataFrame(
    departamento = ["Antioquia", "Cundinamarca", "Valle"],
    area_km2 = [63612, 22623, 22140],
    capital = ["Medellín", "Bogotá", "Cali"]
)
typeof(df_colombia)

# describe() da un resumen estadístico de la tabla
println(describe(df_colombia))
```
:::
:::


```{r}
#| label: objetos_julia_ejecucion
#| results: asis
# #| eval: false
j_eval('
# 1. Vectores: Se definen con corchetes (similar a Python)
codigos = [5, 25, 76]

typeof(codigos)

# 2. Diccionarios: Se usa el operador => para asociar clave y valor
metadatos = Dict(
    "departamento" => ["Antioquia", "Cundinamarca", "Valle"],
    "area_km2" => [63612, 22623, 22140]
)

typeof(metadatos)

# 3. Tablas: En Julia Base se pueden usar vectores de Tuplas Nombradas,
# pero en Geomática siempre usaremos la librería DataFrames
using DataFrames
df_colombia = DataFrame(
    departamento = ["Antioquia", "Cundinamarca", "Valle"],
    area_km2 = [63612, 22623, 22140],
    capital = ["Medellín", "Bogotá", "Cali"]
)

typeof(df_colombia)

# describe() da un resumen estadístico de la tabla
println(describe(df_colombia))
')
```
:::

## 4. Comandos básicos y manipulación de tablas

| Tarea | Descripción | Python | R | Julia |
|---|---|---|---|---|
| Directorio | Ruta de trabajo actual | `os.getcwd()` | `getwd()` | `pwd()` |
| Tipo / clase | Tipo de estructura | `type()` | `class()` | `typeof()` |
| Estructura | Resumen técnico | `df.info()` | `str()` | `describe(df)` |
| Dimensiones | Filas y columnas | `df.shape` | `dim()` | `size()` |
| Primeras filas | Vista rápida inicial | `df.head(n)` | `head(df, n)` | `first(df, n)` |
| Frecuencias | Conteo de categorías | `value_counts()` | `table()` | `countmap()` |
| Unir filas | Concatenar vertical | `pd.concat(..., axis=0)` | `rbind()` | `vcat()` |
| Omitir NA | Limpiar datos faltantes | `dropna()` | `na.omit()` | `dropmissing()` |
| Ordenar | Organizar por columna | `sort_values()` | `order()` / `arrange()` | `sort()` |

::: {.panel-tabset}

### Python
```{python}
#| label: comandos_python
# #| eval: false
import os
import numpy as np
import pandas as pd

# 1. Gestión del entorno de trabajo
print(f"Ruta actual: {os.getcwd()}")

# 2. Creación de datos: Departamentos de Colombia (Población en millones, Área en km2)
data = {
    "depto": ["Antioquia", "Cundinamarca", "Valle", "Bolívar", "Atlántico"],
    "pob_2023": [6.8, 3.2, 4.6, 2.2, 2.8],
    "area_km2": [63612, 22623, 22140, 25978, 3388],
    "region": ["Andina", "Andina", "Pacífica", "Caribe", "Caribe"]
}
df = pd.DataFrame(data)

# 3. Inspección de la tabla
print(df.info())           # Resumen de tipos de datos y memoria
print(f"Forma: {df.shape}") # (filas, columnas)
print(df.head(3))          # Ver los primeros 3 registros

# 4. Análisis de frecuencias (¿Cuántos deptos por región?)
print(df["region"].value_counts())

# 5. Operaciones de unión
# Crear un nuevo registro para un depto faltante
nuevo_depto = pd.DataFrame({"depto":["Chocó"], "pob_2023":[0.5], "area_km2":[46530], "region":["Pacífica"]})
# Concatenar verticalmente (axis=0 es por filas)
df_extendido = pd.concat([df, nuevo_depto], axis=0, ignore_index=True)

# 6. Ordenamiento
# Ordenar por población de mayor a menor
df_sorted = df_extendido.sort_values(by="pob_2023", ascending=False)
print(df_sorted)

# 7. Localización por condición (¿Dónde la población es > 4M?)
indices = np.where(df_extendido["pob_2023"] > 4.0)
print(f"Índices detectados: {indices}")
```

### R
```{r}
#| label: comandos_r
# #| eval: false
# 1. Gestión del entorno
getwd()

# 2. Datos de ejemplo (Departamentos de Colombia)
df <- data.frame(
  depto = c("Antioquia", "Cundinamarca", "Valle", "Bolívar", "Atlántico"),
  pob_2023 = c(6.8, 3.2, 4.6, 2.2, 2.8),
  area_km2 = c(63612, 22623, 22140, 25978, 3388),
  region = c("Andina", "Andina", "Pacífica", "Caribe", "Caribe")
)

# 3. Inspección básica
str(df)          # Estructura del objeto
dim(df)          # Dimensiones (filas y columnas)
head(df, 3)      # Primeras 3 filas

# 4. Frecuencias (Equivalente a value_counts)
table(df$region)

# 5. Uniones verticales
# Creamos el registro adicional
nuevo <- data.frame(depto="Chocó", pob_2023=0.5, area_km2=46530, region="Pacífica")
# rbind une por filas (necesita que las columnas se llamen igual)
df_extendido <- rbind(df, nuevo)

# 6. Ordenamiento
# order() devuelve los índices; los usamos para reindexar el dataframe
df_sorted <- df_extendido[order(-df_extendido$pob_2023), ]
print(df_sorted)

# 7. Alternativa con dplyr (El estándar de "Tidyverse" para manipular tablas)
library(dplyr)

# --- Opción A: Paso a paso con variables intermedias ---
# Útil para depurar y entender qué sucede en cada etapa

# Paso 1: Ordenar la tabla de departamentos por población de forma descendente
df_ordenado <- arrange(df_extendido, desc(pob_2023))
print(df_ordenado)

# Paso 2: Filtrar los resultados para quedarnos solo con los mayores a 4M
df_final <- filter(df_ordenado, pob_2023 > 4.0)
print(df_final)


# --- Opción B: Uso de Operadores Pipe (Flujo continuo) ---
# El pipe permite "pasar" el resultado de una función a la siguiente sin crear variables nuevas.

# 1. Pipe de la librería dplyr (el clásico: %>%)
# Se lee como: "Toma df_extendido, ENTONCES ordena, ENTONCES filtra"
df_extendido %>% 
  arrange(desc(pob_2023)) %>% 
  filter(pob_2023 > 4.0)

# 2. Pipe nativo de R (disponible desde la versión 4.1: |>)
# Es más eficiente en memoria y no depende de cargar librerías extra
df_extendido |> 
  arrange(desc(pob_2023)) |> 
  filter(pob_2023 > 4.0)

```

### Julia

::: {.content-visible when-format="html"}
::: {.callout-tip collapse="true" icon="false"}
#### ▷ CÓDIGO PURO (Copiar y Pegar)
```{julia}
#| label: comandos_julia_codigo
#| eval: false
using DataFrames, Statistics

# 1. Directorio actual
pwd()

# 2. Definición de la tabla de departamentos
df = DataFrame(
    depto = ["Antioquia", "Cundinamarca", "Valle", "Bolívar", "Atlántico"],
    pob_2023 = [6.8, 3.2, 4.6, 2.2, 2.8],
    area_km2 = [63612, 22623, 22140, 25978, 3388],
    region = ["Andina", "Andina", "Pacífica", "Caribe", "Caribe"]
)

# 3. Inspección técnica
describe(df)     # Resumen estadístico y de tipos
nrow(df)         # Número de filas
first(df, 3)     # Primeros 3 registros

# 4. Uniones
nuevo = DataFrame(depto=["Chocó"], pob_2023=[0.5], area_km2=[46530], region=["Pacífica"])
# vcat es concatenación vertical
df_ext = vcat(df, nuevo)

# 5. Ordenamiento (rev=true para descendente)
df_sorted = sort(df_ext, :pob_2023, rev=true)
println(df_sorted)
```
:::
:::

```{r}
#| label: comandos_julia_ejecucion
#| results: asis
# #| eval: false
j_eval('
using DataFrames

# Recreamos la tabla en el entorno de Julia
df = DataFrame(
    depto = ["Antioquia", "Cundinamarca", "Valle", "Bolívar", "Atlántico"],
    pob_2023 = [6.8, 3.2, 4.6, 2.2, 2.8],
    area_km2 = [63612, 22623, 22140, 25978, 3388],
    region = ["Andina", "Andina", "Pacífica", "Caribe", "Caribe"]
)

# Ejecutamos inspección y unión
nuevo = DataFrame(depto=["Chocó"], pob_2023=[0.5], area_km2=[46530], region=["Pacífica"])
df_ext = vcat(df, nuevo)

# Ordenar por población y mostrar
println(sort(df_ext, :pob_2023, rev=true))
')
```
:::

### Operaciones numéricas y matemáticas básicas

En el análisis espacial, estas operaciones son la base para calcular distancias, transformar coordenadas o procesar índices de vegetación (NDVI). A continuación, comparamos la sintaxis para las funciones matemáticas más comunes.

| Tarea | Descripción | Python | R | Julia |
|---|---|---|---|---|
| División entera | Cociente sin decimales | `//` | `%/%` | `div()` |
| Módulo | Residuo de la división | `%` | `%%` | `%` |
| Raíz cuadrada | Cálculo de $x^{1/2}$ | `math.sqrt()` | `sqrt()` | `sqrt()` |
| Logaritmo | Logaritmo natural ($ln$) | `math.log()` | `log()` | `log()` |
| Constantes | Valores de $\pi$ y $e$ | `math.pi`, `math.e`| `pi`, `exp(1)` | `pi`, `exp(1)` |

::: {.panel-tabset}

### Python
```{python}
#| label: operaciones_python
# #| eval: false
import math

# 1. Aritmética entera (Útil para indexación de matrices)
print(f"División entera (5 // 2): {5 // 2}")
print(f"Residuo/Módulo (5 % 2): {5 % 2}")

# 2. Constantes matemáticas universales
print(f"Número e: {math.e}")
print(f"Número pi: {math.pi}")

# 3. Funciones matemáticas (Requieren el módulo math)
print(f"Raíz cuadrada de 2: {math.sqrt(2)}")
print(f"Logaritmo natural de 3: {math.log(3)}")
print(f"Logaritmo base 10 de 3: {math.log(3, 10)}")

# 4. Valor absoluto (Distancia sin dirección)
print(f"Absoluto de -3.4: {abs(-3.4)}")
```

### R
```{r}
#| label: operaciones_r
# #| eval: false

# 1. Aritmética entera
cat("División entera (5 %/% 2):", 5 %/% 2, "\n")
cat("Residuo/Módulo (5 %% 2):", 5 %% 2, "\n")

# 2. Constantes (pi es nativo, e se obtiene con exp)
cat("Número e (exp(1)):", exp(1), "\n")
cat("Número pi:", pi, "\n")

# 3. Funciones matemáticas (Nativas en Base R)
cat("Raíz cuadrada de 2:", sqrt(2), "\n")
cat("Logaritmo natural de 3:", log(3), "\n")
cat("Logaritmo base 10 de 3:", log(3, 10), "\n")

# 4. Valor absoluto
cat("Absoluto de -3.4:", abs(-3.4), "\n")
```

### Julia

::: {.content-visible when-format="html"}
::: {.callout-tip collapse="true" icon="false"}
#### ▷ CÓDIGO PURO (Copiar y Pegar)
```{julia}
#| label: operaciones_julia_codigo
#| eval: false
# 1. Aritmética entera
println("División entera: ", div(5, 2))
println("Residuo: ", 5 % 2)

# 2. Constantes y funciones (Nativas en Julia)
println("Número e: ", exp(1))
println("Número pi: ", pi)

# 3. Funciones matemáticas
println("Raíz cuadrada: ", sqrt(2))
println("Logaritmo natural: ", log(3))
println("Logaritmo base 10: ", log(10, 3)) # Nota: En Julia log(base, x)

# 4. Valor absoluto
println("Absoluto: ", abs(-3.4))
```
:::
:::

```{r}
#| label: operaciones_julia_ejecucion
#| results: asis
# #| eval: false
j_eval('
# Ejecución de operaciones matemáticas vía j_eval
println("División entera Julia: ", div(5, 2))
println("Residuo Julia: ", 5 % 2)
println("Raíz de 2: ", sqrt(2))
println("Log natural 3: ", log(3))
println("Log base 10: ", log(10, 3)) # Inversión de argumentos frente a R/Python
println("Absoluto: ", abs(-3.4))
println("Pi: ", pi)
')
```
:::

## 5. Lectura y escritura de datos

| Tarea | Descripción | Python | R | Julia |
|---|---|---|---|---|
| Leer CSV | Cargar tabla desde texto/archivo | `pd.read_csv()` | `read.csv()` | `CSV.read()` |
| Escribir CSV | Guardar tabla en disco | `df.to_csv()` | `write.csv()` | `CSV.write()` |

Para este ejercicio, utilizaremos una técnica de **simulación de archivos en memoria**. Esto es extremadamente útil en programación SIG para procesar datos que vienen de servicios web (APIs) antes de guardarlos físicamente.

::: {.panel-tabset}

### Python
```{python}
#| label: lectura_python
# #| eval: false
import pandas as pd
from io import StringIO

# Simulamos el contenido de un archivo CSV con municipios y altitudes (msnm)
csv_data = """
municipio,altitud
Bogota,2625
Medellin,1495
Cali,1018
Quibdo,43
"""

# StringIO convierte un texto en un "objeto de archivo" que pandas puede leer
df = pd.read_csv(StringIO(csv_data))

# Mostramos el resultado cargado
print(df)

# Guardamos en el disco (index=False evita que se guarde la columna de índices)
df.to_csv("municipios_altitud.csv", index=False)
```

### R
```{r}
#| label: lectura_r
# #| eval: false
# Contenido simulado
csv_data <- "
municipio,altitud
Bogota,2625
Medellin,1495
Cali,1018
Quibdo,43
"

# textConnection crea un flujo de lectura a partir de la cadena de texto
con <- textConnection(csv_data)
df <- read.csv(con)

# Es buena práctica cerrar la conexión después de usarla
close(con)

# Visualizamos la tabla
print(df)

# Escribimos en el disco (row.names=FALSE para evitar la columna adicional de números)
write.csv(df, "municipios_altitud.csv", row.names = FALSE)
```

### Julia

::: {.content-visible when-format="html"}
::: {.callout-tip collapse="true" icon="false"}
#### ▷ CÓDIGO PURO (Copiar y Pegar)
```{julia}
#| label: lectura_julia_codigo
#| eval: false
using CSV
using DataFrames

# Contenido simulado
csv_data = "
municipio,altitud
Bogota,2625
Medellin,1495
Cali,1018
Quibdo,43
"

# IOBuffer permite a Julia tratar un String como un archivo abierto
df = CSV.read(IOBuffer(csv_data), DataFrame)

# Visualizamos
println(df)

# Guardar datos en el disco
CSV.write("municipios_altitud.csv", df)
```
:::
:::

```{r}
#| label: lectura_julia_ejecucion
#| results: asis
# #| eval: false
j_eval('
using CSV
using DataFrames

csv_data = "
municipio,altitud
Bogota,2625
Medellin,1495
Cali,1018
Quibdo,43
"

# Cargamos el string como DataFrame usando el buffer de memoria
df = CSV.read(IOBuffer(csv_data), DataFrame)

println("Tabla cargada en Julia:")
println(df)

# Escritura física
CSV.write("municipios_altitud.csv", df)
')
```
:::


## 6. Indexación y filtrado

En esta sección aprenderemos a extraer subconjuntos de datos. En Geomática, esto es vital para aislar, por ejemplo, municipios que superen una altitud crítica o departamentos que pertenecen a una región específica.

| Tarea | Descripción | Python | R | Julia |
|---|---|---|---|---|
| Seleccionar filas | Elegir registros por posición | `df.iloc[0:2]` | `df[1:2, ]` | `df[1:2, :]` |
| Filtrar por condición | Subset basado en reglas | `df[df["altitud"] > 1000]` | `df[df$altitud > 1000, ]` | `filter(row -> ...)` |

::: {.panel-tabset}

### Python
```{python}
#| label: indexacion_python
# #| eval: false
import pandas as pd

# Datos de municipios colombianos con su altitud (msnm)
df = pd.DataFrame({
    "municipio": ["Bogotá", "Medellín", "Cali", "Quibdó", "Barranquilla"],
    "altitud": [2625, 1495, 1018, 43, 18],
    "departamento": ["Cundinamarca", "Antioquia", "Valle", "Chocó", "Atlántico"]
})

# 1. Seleccionar filas por posición (índices 0 y 1)
# iloc permite acceso puramente posicional
primeros_dos = df.iloc[0:2]
print("Primeros dos municipios:\n", primeros_dos)

# 2. Filtrar por condición (Municipios de "Tierras Altas" > 1500 msnm)
tierras_altas = df[df["altitud"] > 1500]
print("\nMunicipios en tierras altas:\n", tierras_altas)

# 3. Filtrado con múltiples condiciones (Andinos y con altitud > 1000)
# Usamos & para 'y' lógico
andinos_altos = df[(df["altitud"] > 1000) & (df["departamento"] != "Chocó")]
```

### R
```{r}
#| label: indexacion_r
# #| eval: false
df <- data.frame(
  municipio = c("Bogotá", "Medellín", "Cali", "Quibdó", "Barranquilla"),
  altitud = c(2625, 1495, 1018, 43, 18),
  departamento = c("Cundinamarca", "Antioquia", "Valle", "Chocó", "Atlántico")
)

# 1. Seleccionar filas por posición (En R los índices inician en 1)
primeros_dos <- df[1:2, ]
print(primeros_dos)

# 2. Filtrar por condición lógica
tierras_altas <- df[df$altitud > 1500, ]
print(tierras_altas)

# 3. Filtrado usando subset() - más legible en Base R
andinos_altos <- subset(df, altitud > 1000 & departamento != "Chocó")
print(andinos_altos)
```

### Julia

::: {.content-visible when-format="html"}
::: {.callout-tip collapse="true" icon="false"}
#### ▷ CÓDIGO PURO (Copiar y Pegar)
```{julia}
#| label: indexacion_julia_codigo
#| eval: false
using DataFrames

df = DataFrame(
    municipio = ["Bogotá", "Medellín", "Cali", "Quibdó", "Barranquilla"],
    altitud = [2625, 1495, 1018, 43, 18],
    departamento = ["Cundinamarca", "Antioquia", "Valle", "Chocó", "Atlántico"]
)

# 1. Selección por posición (similar a R, inicia en 1)
primeros_dos = df[1:2, :]

# 2. Filtrado usando la función filter()
# El operador -> crea una función anónima para evaluar cada fila
tierras_altas = filter(row -> row.altitud > 1500, df)

# 3. Filtrado abreviado (Sintaxis de Julia 1.7+)
andinos_altos = df[(df.altitud .> 1000) .& (df.departamento .!= "Chocó"), :]
```
:::
:::

```{r}
#| label: indexacion_julia_ejecucion
#| results: asis
# #| eval: false
j_eval('
using DataFrames

df = DataFrame(
    municipio = ["Bogotá", "Medellín", "Cali", "Quibdó", "Barranquilla"],
    altitud = [2625, 1495, 1018, 43, 18],
    departamento = ["Cundinamarca", "Antioquia", "Valle", "Chocó", "Atlántico"]
)

# Ejecutamos un filtro y mostramos el resultado
println("Municipios con altitud > 1000 msnm:")
println(filter(row -> row.altitud > 1000, df))
')
```
:::

## 7. Estadística descriptiva básica

El análisis estadístico permite entender la distribución de variables geográficas, como la precipitación acumulada o la densidad de población.

| Tarea | Descripción | Python | R | Julia |
|---|---|---|---|---|
| Media | Promedio aritmético | `np.mean()` | `mean()` | `mean()` |
| Desviación | Medida de dispersión | `np.std()` | `sd()` | `std()` |
| Resumen | Estadísticos básicos | `df.describe()` | `summary()` | `describe()` |

::: {.panel-tabset}

### Python
```{python}
#| label: estadistica_python
# #| eval: false
import numpy as np
import pandas as pd

# Altitudes de una muestra de estaciones climáticas en los Andes colombianos
altitudes = np.array([2625, 1495, 1018, 2150, 1850])

# 1. Estadísticos individuales con Numpy
print(f"Altitud Media: {np.mean(altitudes)} msnm")
print(f"Desviación Estándar: {np.std(altitudes):.2f}")

# 2. Resumen completo con Pandas
df_alt = pd.DataFrame(altitudes, columns=["msnm"])
print("\nResumen Descriptivo:")
print(df_alt.describe())
```

### R
```{r}
#| label: estadistica_r
# #| eval: false
# Vector de altitudes msnm
altitudes <- c(2625, 1495, 1018, 2150, 1850)

# 1. Estadísticos descriptivos básicos
cat("Media:", mean(altitudes), "\n")
cat("Desviación Estándar:", sd(altitudes), "\n")

# 2. Resumen completo (Min, 1st Qu, Median, Mean, 3rd Qu, Max)
summary(altitudes)
```

### Julia

::: {.content-visible when-format="html"}
::: {.callout-tip collapse="true" icon="false"}
#### ▷ CÓDIGO PURO (Copiar y Pegar)
```{julia}
#| label: estadistica_julia_codigo
#| eval: false
using Statistics
using DataFrames

altitudes = [2625, 1495, 1018, 2150, 1850]

# 1. Las funciones de estadística requieren el paquete 'Statistics'
println("Media: ", mean(altitudes))
println("Desviación: ", std(altitudes))

# 2. Resumen descriptivo para DataFrames
df = DataFrame(msnm = altitudes)
println(describe(df))
```
:::
:::

```{r}
#| label: estadistica_julia_ejecucion
#| results: asis
# #| eval: false
j_eval('
using Statistics
using DataFrames

altitudes = [2625, 1495, 1018, 2150, 1850]

println("Media aritmética en Julia: ", mean(altitudes))
println("Desviación estándar: ", std(altitudes))

# Mostramos el resumen tabular
df = DataFrame(msnm = altitudes)
println(describe(df))
')
```
:::


## 8. Gráficos básicos

La visualización es el primer paso del análisis exploratorio de datos (EDA). En SIG, usamos barras para comparar atributos entre regiones y los histogramas para entender la distribución de variables como la elevación o la precipitación.

| Tarea | Descripción | Python | R | Julia |
|---|---|---|---|---|
| Barras | Comparar categorías | `plt.bar()` | `barplot()` | `bar()` |
| Histograma | Distribución de frecuencias | `plt.hist()` | `hist()` | `histogram()` |

::: {.panel-tabset}

### Python
```{python}
#| label: graficos_python
# #| eval: false
import matplotlib.pyplot as plt

# 1. Gráfico de Barras: Altitud de ciudades principales
ciudades = ["Bogotá", "Medellín", "Cali", "Quibdó"]
altitudes = [2625, 1495, 1018, 43]

plt.bar(ciudades, altitudes, color='skyblue', edgecolor='navy')
plt.xlabel("Ciudad")
plt.ylabel("Altitud (msnm)")
plt.title("Comparativa de Altitud - Municipios de Colombia")
plt.show()

# 2. Histograma: Distribución de una muestra de altitudes
# Simulamos 50 estaciones climáticas en diferentes pisos térmicos
import numpy as np
muestra_altitudes = [2625, 1495, 1018, 43, 18, 2527, 959, 467, 2150, 1850] * 5

plt.hist(muestra_altitudes, bins=5, color='orange', alpha=0.7)
plt.xlabel("Rango de Altitud (msnm)")
plt.ylabel("Frecuencia (N° Estaciones)")
plt.title("Distribución de Estaciones por Altitud")
plt.show()
```

### R
```{r}
#| label: graficos_r
# #| eval: false
# 1. Gráfico de Barras
ciudades <- c("Bogotá", "Medellín", "Cali", "Quibdó")
altitudes <- c(2625, 1495, 1018, 43)

# En R base, barplot es simple y potente
barplot(altitudes, 
        names.arg = ciudades, 
        col = "skyblue", 
        border = "navy",
        xlab = "Ciudad", 
        ylab = "Altitud (msnm)",
        main = "Altitud de Municipios")

# 2. Histograma
muestra_altitudes <- c(2625, 1495, 1018, 43, 18, 2527, 959, 467, 2150, 1850)
hist(muestra_altitudes, 
     breaks = 5, 
     col = "orange", 
     xlab = "Altitud (msnm)", 
     main = "Distribución de la Muestra")
```

### Julia

::: {.content-visible when-format="html"}
::: {.callout-tip collapse="true" icon="false"}
#### ▷ CÓDIGO PURO (Copiar y Pegar)
```{julia}
#| label: graficos_julia_codigo
#| eval: false
using Plots

# 1. Gráfico de Barras
ciudades = ["Bogotá", "Medellín", "Cali", "Quibdó"]
altitudes = [2625, 1495, 1018, 43]

# Plots.jl usa una sintaxis muy limpia para etiquetas
bar(ciudades, altitudes, 
    color=:skyblue, 
    xlabel="Ciudad", 
    ylabel="Altitud (msnm)", 
    title="Altitud de Municipios",
    legend=false)

# 2. Histograma
muestra_altitudes = [2625, 1495, 1018, 43, 18, 2527, 959, 467, 2150, 1850]
histogram(muestra_altitudes, 
          bins=5, 
          color=:orange, 
          title="Frecuencia de Altitudes")
```
:::
:::


```{r}
#| label: graficos_julia_ejecucion
#| echo: true
#| fig-align: "center"
#| out-width: "85%"

# 1. Usamos j_eval para procesar la lógica sin que j_plot interfiera
j_eval('
    # Modo silencioso para el servidor gráfico
    ENV["GKSwstype"] = "100" 
    
    using Plots
    gr()

    # Datos
    ciudades = ["Bogotá", "Medellín", "Cali", "Quibdó"]
    altitudes = [2625, 1495, 1018, 43]

    # Creamos los objetos de gráfico explícitamente
    p1 = bar(ciudades, altitudes, title="Altitud Municipios", legend=false)
    muestra = [2625, 1495, 1018, 43, 18, 2527, 959, 467, 2150, 1850]
    p2 = histogram(muestra, bins=5, title="Histograma Altitudes")

    # Los combinamos en un objeto final
    p_final = plot(p1, p2, layout = (1, 2), size = (800, 400))

    # Guardamos el objeto p_final directamente. 
    # Esto evita el error "No current plot" porque no dependemos del estado global.
    savefig(p_final, "temp_grafica_julia.png")
')

# 2. R se encarga de mostrar la imagen con el formato que pediste
knitr::include_graphics("temp_grafica_julia.png")
```

:::

## 9. Transformación de datos

En el análisis de datos espaciales, frecuentemente necesitamos derivar nuevas variables a partir de las existentes, como convertir unidades de medida (metros a pies) o categorizar valores (crear rangos climáticos).

| Tarea | Descripción | Python | R | Julia |
|---|---|---|---|---|
| Crear columna | Nueva variable calculada | `df["nueva"] = ...` | `df$nueva <- ...` | `df.nueva = ...` |

::: {.panel-tabset}

### Python
```{python}
#| label: transformacion_python
# #| eval: false
import pandas as pd

# Definimos un DataFrame con municipios y su altitud en metros (msnm)
df = pd.DataFrame({
    "municipio": ["Bogotá", "Medellín", "Cali"],
    "altitud_m": [2625, 1495, 1018]
})

# 1. Creación de una columna mediante una operación aritmética simple
# Convertimos metros a pies (aprox. 3.28 pies por metro)
df["altitud_ft"] = df["altitud_m"] * 3.28

# 2. Creación de una columna con lógica condicional (Clasificación climática)
# Usamos una función lambda para evaluar cada fila
df["clima"] = df["altitud_m"].apply(lambda x: "Frío" if x > 2000 else "Templado")

print(df)
```

### R
```{r}
#| label: transformacion_r
# #| eval: false
# Creamos el data frame base
df <- data.frame(
  municipio = c("Bogotá", "Medellín", "Cali"),
  altitud_m = c(2625, 1495, 1018)
)

# 1. Creación de columna usando el operador de asignación $
# La operación se aplica de forma vectorizada a toda la columna
df$altitud_ft <- df$altitud_m * 3.28

# 2. Creación de columna con lógica condicional usando ifelse()
df$clima <- ifelse(df$altitud_m > 2000, "Frío", "Templado")

print(df)
```

### Julia

::: {.content-visible when-format="html"}
::: {.callout-tip collapse="true" icon="false"}
#### ▷ CÓDIGO PURO (Copiar y Pegar)
```{julia}
#| label: transformacion_julia_codigo
#| eval: false
using DataFrames

# Definimos el DataFrame con datos de Colombia
df = DataFrame(
    municipio = ["Bogotá", "Medellín", "Cali"],
    altitud_m = [2625, 1495, 1018]
)

# 1. Creación de columna: El punto (.) indica que la operación es vectorizada (broadcast)
# Es fundamental en Julia para operar sobre todos los elementos de la columna
df.altitud_ft = df.altitud_m .* 3.28

# 2. Creación con lógica condicional usando una comprensión de lista
df.clima = [x > 2000 ? "Frío" : "Templado" for x in df.altitud_m]

println(df)
```
:::
:::

```{r}
#| label: transformacion_julia_ejecucion
#| results: asis
# #| eval: false
j_eval('
using DataFrames

# Recreamos el DataFrame en el entorno de Julia
df = DataFrame(
    municipio = ["Bogotá", "Medellín", "Cali"],
    altitud_m = [2625, 1495, 1018]
)

# Aplicamos las transformaciones
df.altitud_ft = df.altitud_m .* 3.28
df.clima = [x > 2000 ? "Frío" : "Templado" for x in df.altitud_m]

# Mostramos el resultado final
println(df)
')
```
:::


## 10. Resumen comparativo (cheat sheet)

Esta tabla sirve como guía de referencia rápida para transitar entre los tres lenguajes durante el desarrollo de proyectos de análisis espacial.

| Categoría | Tarea | Python | R | Julia |
|---|---|---|---|---|
| **Ecosistema** | Ayuda de función | `help(f)` | `?f` | `?f` |
| | Instalar paquete | `pip3 install x` | `install.packages("x")` | `Pkg.add("x")` |
| **Estructuras** | Vector / Lista | `[1, 2, 3]` | `c(1, 2, 3)` | `[1, 2, 3]` |
| | Diccionario / Mapa | `{"k": v}` | `list(k = v)` | `Dict(k => v)` |
| | Data Frame | `pd.DataFrame(d)` | `data.frame(d)` | `DataFrame(d)` |
| **I/O** | Leer CSV | `pd.read_csv("f.csv")` | `read.csv("f.csv")` | `CSV.read("f.csv", DF)` |
| **Manipulación**| Ver estructura | `df.info()` | `str(df)` | `describe(df)` |
| | Filtrar filas | `df[df.col > x]` | `df[df$col > x, ]` | `filter(r -> r.col > x, df)`|
| | Crear columna | `df["n"] = x * 2` | `df$n <- x * 2` | `df.n = x .* 2` |
| **Análisis** | Media | `np.mean(x)` | `mean(x)` | `mean(x)` |
| | Dimensiones | `df.shape` | `dim(df)` | `size(df)` |
| **Visualización**| Barras | `plt.bar(x, y)` | `barplot(y, names=x)`| `bar(x, y)` |


### Observaciones finales

Para evitar errores comunes en el procesamiento de datos geoespaciales, tenga siempre en cuenta estos tres pilares de la programación moderna:

#### 1. Índices de arreglos (posicionamiento)
La forma en que los lenguajes cuentan las posiciones es la causa principal de errores en la extracción de coordenadas o píxeles:

* **Python:** Utiliza indexación **base-0** (el primer elemento está en la posición `0`).
* **R:** Utiliza indexación **base-1** (el primer elemento está en la posición `1`).
* **Julia:** Al igual que R, utiliza indexación **base-1**.



#### 2. Vectorización y broadcasting (eficiencia)
La capacidad de operar sobre columnas completas sin usar bucles manuales (que son lentos) varía en su sintaxis y naturaleza:

* **Python:** La vectorización **no es nativa** de las listas base. Depende totalmente de librerías como `numpy` o `pandas`. Si intenta multiplicar una lista estándar por 2 (`[1, 2] * 2`), Python duplicará los elementos de la lista en lugar de realizar el cálculo matemático.
* **R:** La vectorización es **nativa y automática**. Casi todas las funciones de R están diseñadas para recibir un vector y devolver otro. Al hacer `vector * 2`, R entiende por defecto que debe multiplicarse cada elemento.
* **Julia:** Utiliza el concepto de **Broadcasting**. Es el más explícito: requiere añadir un **punto** antes del operador (`.*`, `./`, `.^`) o de la función. Este punto le indica al compilador de Julia que "esparza" la operación sobre todos los elementos del vector con una eficiencia comparable al lenguaje C.



#### 3. El flujo de datos: el **pipe** (`.`, `%>%`, `|>`)
El "Pipe" permite escribir código que se lee de izquierda a derecha (como una receta), evitando el anidamiento excesivo de paréntesis.

* **Python (`pandas`):** Utiliza el **encadenamiento de métodos** mediante el punto (`.`). Cada operación devuelve un nuevo objeto sobre el cual se aplica la siguiente: `df.filter(...).sort(...)`.
* **R (`dplyr` / Nativo):** El pipe clásico de *Tidyverse* (`%>%`) o el nativo (`|>`) pasa el objeto automáticamente como **primer argumento** de la siguiente función: `df %>% filter(...)`.
* **Julia (`|>` / `Chain.jl`):** El pipe nativo (`|>`) es un operador de tubería simple. Para flujos de datos complejos y legibles, la comunidad de Julia prefiere la macro `@chain` del paquete `Chain.jl`.

---

### Librerías de referencia (caja de herramientas)

Para que su entorno de trabajo esté completo, asegúrese de tener instaladas y cargadas estas librerías base:

1.  **Python:** `pandas` (tablas de atributos), `numpy` (álgebra de mapas), `matplotlib` (salidas gráficas).
2.  **R:** `base` y `dplyr` (manipulación), `graphics` (visualización rápida).
3.  **Julia:** `DataFrames` (tablas), `CSV` (lectura), `Statistics` y `Plots`.

> **Nota sobre el rendimiento:** Ninguno de los comandos vistos en este capítulo ejecuta procesamiento en paralelo (uso de múltiples núcleos). La vectorización y el pipe son herramientas de **eficiencia lógica y computacional en un solo núcleo**. El procesamiento multihilo se reservará para el análisis de grandes volúmenes de datos en capítulos posteriores.


## Ejercicios

Para poner en práctica los conceptos introductorios abordados en este capítulo, deberás resolver los siguientes dos ejercicios. Puedes elegir resolverlos en **Python, R o Julia** (o implementar la solución en varios lenguajes si deseas retarte).

### Ejercicio 1: Hidrología del Río Magdalena (Vectores y Matemáticas)

**Contexto:** Estás analizando el comportamiento de las estaciones hidrológicas del IDEAM a lo largo del Río Magdalena. Has recibido el reporte del caudal medio mensual (en metros cúbicos por segundo, $m^3/s$) de cinco estaciones clave y necesitas extraer estadísticos básicos y transformar las unidades para un informe ambiental.

**Instrucciones de código:**

1. Define una colección ordenada (Vector/Lista/Array) llamada `estaciones` con los siguientes nombres: `"Honda", "Puerto Berrío", "Barrancabermeja", "Puerto Wilches", "Calamar"`.
2. Define otra colección paralela llamada `caudales_m3s` con los siguientes valores numéricos: `1500, 2100, 2800, 3200, 4500`.
3. Utilizando las funciones estadísticas nativas de tu lenguaje elegido, calcula e imprime:
   * El **caudal máximo** registrado en el río.
   * El **caudal promedio** de las cinco estaciones.
4. Para un estudio local, necesitas el caudal en **litros por segundo (l/s)**. Utilizando el concepto de *vectorización* (o *broadcasting*), multiplica la colección `caudales_m3s` por `1000` y guarda el resultado en una nueva variable llamada `caudales_ls`. (Asegúrate de no usar bucles `for`).
5. Imprime la colección resultante `caudales_ls`.

### Ejercicio 2: Calidad del Aire en Bogotá (DataFrames y Filtrado)

**Contexto:** La Red de Monitoreo de Calidad del Aire de Bogotá ha publicado los datos promedio diarios de Material Particulado 2.5 ($PM_{2.5}$). Debes organizar estos datos en una estructura tabular, filtrar las estaciones que presentan riesgos para la salud (según la OMS) y visualizar los resultados.

**Instrucciones de código:**

1. Crea un **DataFrame** llamado `df_aire` (utilizando la librería adecuada según tu lenguaje: `pandas`, `data.frame` o `DataFrames.jl`) que contenga dos columnas:
   * `estacion`: `"Carvajal", "Kennedy", "Fontibón", "Suba", "Usaquén"`
   * `pm25`: `55, 42, 38, 15, 12`
2. Imprime un **resumen descriptivo/técnico** de tu DataFrame (usando la función equivalente a `info()`, `str()` o `describe()`).
3. El límite diario recomendado por la OMS para $PM_{2.5}$ es de 15 $\mu g/m^3$. Crea un nuevo DataFrame llamado `df_alerta` que **filtre** y contenga únicamente las estaciones donde el nivel de `pm25` sea **estrictamente mayor a 15**.
4. Crea una **nueva columna** en `df_alerta` llamada `estado` y asígnale a todas sus filas el valor de texto `"Crítico"`.
5. Utiliza la librería gráfica nativa de tu entorno para generar un **gráfico de barras** simple usando el DataFrame original (`df_aire`), donde el eje X sean las estaciones y el eje Y sean los niveles de $PM_{2.5}$.

### Entregables y Criterios de Evaluación

El objetivo de esta evaluación no es solo que el código funcione, sino que seas capaz de documentar y explicar las diferencias fundamentales entre lenguajes.

**1. Archivos de Código:**
Debes desarrollar los algoritmos en al menos uno de los siguientes formatos de archivo:

* Script tradicional (`.py`, `.R`, `.jl`)
* Notebook interactivo (`.ipynb`)
* Documento computacional (`.qmd` con *chunks* de código)

**2. Documento Analítico (Quarto):**
Independientemente del formato de tu código fuente, **debes redactar un documento en Quarto (`.qmd`) y renderizarlo tanto en HTML como en PDF**. En este documento debes incluir tus bloques de código y responder argumentativamente a las siguientes preguntas:

* **Sobre el Ejercicio 1 (Vectorización):** Intenta explicar qué sucedería si decides hacer este ejercicio en **Python** y creas `caudales_m3s` como una Lista nativa (`[1500, 2100...]`) y la multiplicas directamente por 1000 (`caudales_m3s * 1000`). ¿Realizaría la operación matemática deseada? ¿Qué librería de Python soluciona este problema y cómo se diferencia este comportamiento del de R o Julia?
* **Pregunta General (Indexación):** Escribe la línea de código exacta que usarías en tu lenguaje elegido para extraer **las tres primeras estaciones** del DataFrame del Ejercicio 2 usando indexación por rangos (*slicing*). Explica brevemente si el límite superior del rango que escribiste se incluye o se excluye en el resultado final, justificando esto según el tipo de indexación (Base-0 vs Base-1) de tu lenguaje.

**3. Repositorio en GitHub:**
Sube tu carpeta del proyecto (que debe contener tus scripts, el archivo `.qmd` y los renders finales en HTML y PDF) a un repositorio público en tu cuenta personal de **GitHub**.

* **Entrega:** Deberás enviar únicamente el enlace (URL) a tu repositorio de GitHub para la calificación.
